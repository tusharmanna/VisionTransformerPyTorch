{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklear and pytorch libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import requests\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    recall_score,roc_auc_score,\n",
    "    log_loss,\n",
    "    balanced_accuracy_score,\n",
    "    jaccard_score\n",
    ")\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate pillow torchvision scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = \"https://github.com/tusharmanna/VisionTransformerPyTorch/tree/main/Testing/Testing\"\n",
    "train_images = \"https://github.com/tusharmanna/VisionTransformerPyTorch/tree/main/Training/Training\"\n",
    "validation_images = \"https://github.com/tusharmanna/VisionTransformerPyTorch/tree/main/Validation/Validation\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BeautifulSoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[198], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     exit(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Parse HTML to extract image file URLs\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m image_urls \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Find all links to images\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BeautifulSoup' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the HTML content from the GitHub page\n",
    "response = requests.get(train_images)\n",
    "if response.status_code != 200:\n",
    "    print(f\"Failed to retrieve the page: {response.status_code}\")\n",
    "    exit(1)\n",
    "\n",
    "# Parse HTML to extract image file URLs\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "image_urls = []\n",
    "\n",
    "# Find all links to images\n",
    "for link in soup.find_all('a', href=True):\n",
    "    href = link['href']\n",
    "    if href.endswith(('.jpg', '.jpeg', '.png', '.gif')):  # Check for image extensions\n",
    "        # Construct the raw URL\n",
    "        raw_url = f\"https://raw.githubusercontent.com{href.replace('/blob', '')}\"\n",
    "        image_urls.append(raw_url)\n",
    "\n",
    "print(f\"Found {len(image_urls)} image files.\")\n",
    "\n",
    "\n",
    "# Download each image\n",
    "for i,url in image_urls[:10]:\n",
    "    image_name = os.path.join(local_path, os.path.basename(url))\n",
    "    try:\n",
    "        img_data = requests.get(url).content\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(mpimg.imread(BytesIO(img_data)))\n",
    "        plt.axis('off')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
